{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi!\n",
      "FIT-agg-X: <class 'pandas.core.frame.DataFrame'>\n",
      "TRANSFORM-agg-X: <class 'pandas.core.frame.DataFrame'>\n",
      "FIT-COST-X: <class 'pandas.core.frame.DataFrame'>\n",
      "TRANSFORM-COST-X:    square_footage neighborhood  avg_sqft_per_neighborhood\n",
      "4            3000            A                2333.333333\n",
      "2            2500            A                2333.333333\n",
      "0            1500            A                2333.333333\n",
      "3            1800            B                1800.000000\n",
      "bye!\n",
      "TRANSFORM-agg-X: <class 'pandas.core.frame.DataFrame'>\n",
      "TRANSFORM-COST-X:    square_footage neighborhood  avg_sqft_per_neighborhood\n",
      "1            2000            B                     1800.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheng\\Workspace\\Paramount\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "2025/01/25 10:08:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete: RMSE=9999.999999999942, R2=nan\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'square_footage': [1500, 2000, 2500, 1800, 3000],\n",
    "    'price': [300000, 400000, 500000, 350000, 600000],\n",
    "    'neighborhood': ['A', 'B', 'A', 'B', 'A']\n",
    "})\n",
    "\n",
    "# Train-test split\n",
    "X = data[['square_footage', 'neighborhood']]\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class GroupAverageTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_col, target_col, new_feature_name):\n",
    "        self.group_col = group_col  # The categorical column for grouping\n",
    "        self.target_col = target_col  # The target column for aggregation\n",
    "        self.new_feature_name = new_feature_name  # The name of the new feature\n",
    "        self.group_averages_ = {}  # To store the hash map of group averages\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Check if the required columns exist in the DataFrame\n",
    "        print(\"FIT-agg-X:\", type(X))\n",
    "        if self.group_col not in X.columns or self.target_col not in X.columns:\n",
    "            raise ValueError(f\"Columns {self.group_col} and {self.target_col} must exist in the DataFrame.\")\n",
    "\n",
    "        # Compute group-level averages based on the training data\n",
    "        self.group_averages_ = (\n",
    "            X.groupby(self.group_col)[self.target_col].mean().to_dict()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        print(\"TRANSFORM-agg-X:\", type(X))\n",
    "        # Add the new feature by mapping group averages\n",
    "        X[self.new_feature_name] = X[self.group_col].map(self.group_averages_)\n",
    "\n",
    "        # Handle rows where the group is not found in training data (e.g., in X_test)\n",
    "        global_mean = X_train['square_footage'].mean()  # Example: 1950.0\n",
    "        X_test['avg_sqft_per_neighborhood'] = X_test['neighborhood'].map(self.group_averages_).fillna(global_mean)\n",
    "\n",
    "\n",
    "        return X\n",
    "\n",
    "class CostPerSquareFootTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"FIT-COST-X:\", type(X))\n",
    "        if y is None:\n",
    "            raise ValueError(\"Target values (y) must not be None during fit.\")\n",
    "        # Use only the mean of the training target (y) to compute the mean price\n",
    "        self.mean_price_ = y.mean()  # Save the mean price from training set\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"TRANSFORM-COST-X:\", X)\n",
    "        X = X.copy()\n",
    "        # Use the mean price from the training data to calculate the feature\n",
    "        X['cost_per_square_foot'] = X['square_footage'] / (self.mean_price_ + 1e-9)\n",
    "        return X\n",
    "\n",
    "# Preprocessing pipeline - CONVERTS DATAFRAME INTO NUMPY ARRAY\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['square_footage', 'cost_per_square_foot']),\n",
    "        ('cat', OneHotEncoder(), ['neighborhood'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('group_avg', GroupAverageTransformer(\n",
    "        group_col='neighborhood',\n",
    "        target_col='square_footage',\n",
    "        new_feature_name='avg_sqft_per_neighborhood'\n",
    "    )),\n",
    "    ('cost_per_sqft_transformer', CostPerSquareFootTransformer()),  # Custom feature engineering\n",
    "    ('preprocessor', preprocessor),  # Preprocessing\n",
    "    ('model', LinearRegression())  # Model\n",
    "])\n",
    "\n",
    "# Train the model with MLflow tracking\n",
    "with mlflow.start_run():\n",
    "    # Fit the pipeline\n",
    "    print(\"hi!\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"bye!\")\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log the entire pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"pipeline_model\")\n",
    "\n",
    "    # End the run\n",
    "    print(f\"Run complete: RMSE={rmse}, R2={r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheng\\Workspace\\Paramount\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "2025/01/25 11:24:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete: RMSE=9999.999999999942, R2=nan\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Issues and Opportunities for Improvement\n",
    " I. DataFrame to NumPy Array Conversions:\n",
    "    Opportunity: Your ColumnTransformer converts the DataFrame into a NumPy array, which breaks compatibility with your custom transformers\n",
    "    that expect a DataFrame (GroupAverageTransformer and CostPerSquareFootTransformer).\n",
    "    Solution: Keep the entire pipeline compatible with DataFrames until the model step, avoiding unnecessary conversions.\n",
    "\n",
    " II. Global Mean Calculation:\n",
    "    Opportunity: In GroupAverageTransformer, you hardcode the calculation of the global mean (X_train['square_footage'].mean()) outside the pipeline.\n",
    "    Solution: Integrate the global mean calculation into the transformer's fit method to make the pipeline self-contained and portable.\n",
    "\n",
    " III. Custom Transformers Handling Columns:\n",
    "    Opportunity: Your custom transformers assume the input is a DataFrame, but later steps (e.g., preprocessor) convert it into a NumPy array.\n",
    "    Solution: Ensure compatibility by making the custom transformers flexible enough to handle both DataFrames and NumPy arrays.\n",
    "\n",
    " IV. Redundancy:\n",
    "    Opportunity: Reundant X.copy() Calls\n",
    "    Solution: Multiple copies of the input DataFrame are created unnecessarily, which can be avoided.\n",
    "\n",
    " V. MLflow Integration:\n",
    "    Opportunity: The pipeline is logged as a whole, but tracking individual components (e.g., feature importance) could provide more insights.\n",
    "    Solution: tracking feature importance or coefficients could enhance interpretability.\n",
    "'''\n",
    "'''\n",
    "Improvements in This Version\n",
    " I. Self-Contained Pipeline:\n",
    "    a. The GroupAverageTransformer now computes the global mean during the fit step, removing the need for external logic.\n",
    " II. Robust Feature Engineering:\n",
    "    a. Both custom transformers (GroupAverageTransformer and CostPerSquareFootTransformer) handle only their specific logic and avoid redundancy.\n",
    "    a. All transformations are self-contained and compatible with both training and test datasets.\n",
    " III. Preprocessor Compatibility:\n",
    "    a. Data remains a DataFrame until it reaches the preprocessor, which transforms it into a NumPy array for model compatibility.\n",
    " IV. Efficient MLflow Logging:\n",
    "    a. Includes coefficients from the linear regression model for better interpretability.\n",
    " V. Avoids Redundant Copies:\n",
    "    a. X.copy() is only called when absolutely necessary.\n",
    "\n",
    "\n",
    "Why Is This More Efficient?\n",
    "    a. Less Overhead: Minimal DataFrame-to-NumPy conversions.\n",
    "    b. Flexible Transformers: Transformers operate on both training and test data seamlessly.\n",
    "    c. End-to-End Integration: All logic resides within the pipeline, making it portable and easy to deploy.\n",
    "'''\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'square_footage': [1500, 2000, 2500, 1800, 3000],\n",
    "    'price': [300000, 400000, 500000, 350000, 600000],\n",
    "    'neighborhood': ['A', 'B', 'A', 'B', 'A']\n",
    "})\n",
    "\n",
    "# Train-test split\n",
    "X = data[['square_footage', 'neighborhood']]\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom transformer for group averages\n",
    "class GroupAverageTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_col, target_col, new_feature_name):\n",
    "        self.group_col = group_col\n",
    "        self.target_col = target_col\n",
    "        self.new_feature_name = new_feature_name\n",
    "        self.group_averages_ = {}\n",
    "        self.global_mean_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate group averages and global mean\n",
    "        self.group_averages_ = X.groupby(self.group_col)[self.target_col].mean().to_dict()\n",
    "        self.global_mean_ = X[self.target_col].mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()  # Avoid modifying the original DataFrame\n",
    "        # Map group averages, fallback to global mean for unknown groups\n",
    "        X[self.new_feature_name] = X[self.group_col].map(self.group_averages_).fillna(self.global_mean_)\n",
    "        return X\n",
    "\n",
    "# Custom transformer for cost per square foot\n",
    "class CostPerSquareFootTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mean_price_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the mean price from the training data\n",
    "        self.mean_price_ = y.mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['cost_per_square_foot'] = X['square_footage'] / (self.mean_price_ + 1e-9)\n",
    "        return X\n",
    "\n",
    "# Preprocessor for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['square_footage', 'cost_per_square_foot']),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), ['neighborhood'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('group_avg', GroupAverageTransformer(\n",
    "        group_col='neighborhood',\n",
    "        target_col='square_footage',\n",
    "        new_feature_name='avg_sqft_per_neighborhood'\n",
    "    )),\n",
    "    ('cost_per_sqft_transformer', CostPerSquareFootTransformer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model with MLflow tracking\n",
    "with mlflow.start_run():\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log the pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"pipeline_model\")\n",
    "\n",
    "    # Log model coefficients\n",
    "    model = pipeline.named_steps['model']\n",
    "    if hasattr(model, 'coef_'):\n",
    "        mlflow.log_param(\"coefficients\", model.coef_.tolist())\n",
    "\n",
    "    print(f\"Run complete: RMSE={rmse}, R2={r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
